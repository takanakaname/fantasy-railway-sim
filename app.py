import streamlit as st
import json
import numpy as np
import pandas as pd
import math
import re
import networkx as nx
from io import BytesIO

# ==========================================
# è¨­å®šãƒ»å®šæ•°
# ==========================================
st.set_page_config(page_title="ç©ºæƒ³é‰„é“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ (ç›´é€šå¯¾å¿œ)", layout="wide")

# åŒä¸€é§…ã¨ã¿ãªã™æœ€å¤§è·é›¢ (ãƒ¡ãƒ¼ãƒˆãƒ«)
SAME_STATION_THRESHOLD = 1000.0

VEHICLE_DB = {
    "æ¨™æº–çš„ãªç§é‰„è»Šä¸¡ (ä¾‹: ã“ã¨ã§ã‚“1200å½¢)": {
        "max_speed": 85.0, "acc": 2.5, "dec": 3.5, "curve_factor": 4.0,
        "desc": "åœ°æ–¹ç§é‰„ã§ã‚ˆãè¦‹ã‚‹æ¨™æº–çš„ãªæ€§èƒ½ã€‚æœ€é«˜é€Ÿã¯æ§ãˆã‚ã€‚"
    },
    "è¿‘éƒŠå‹é›»è»Š (ä¾‹: å›½é‰„115ç³»)": {
        "max_speed": 110.0, "acc": 2.0, "dec": 3.5, "curve_factor": 3.9,
        "desc": "å›½é‰„æ™‚ä»£ã®ä»£è¡¨çš„ãªè¿‘éƒŠå‹é›»è»Šã€‚åŠ é€Ÿã¯éˆã„ãŒæœ€é«˜é€Ÿã¯å‡ºã‚‹ã€‚"
    },
    "é«˜æ€§èƒ½é€šå‹¤é›»è»Š (ä¾‹: JR E233ç³»)": {
        "max_speed": 120.0, "acc": 3.0, "dec": 4.2, "curve_factor": 4.5,
        "desc": "é¦–éƒ½åœã®ä¸»åŠ›è»Šä¸¡ã€‚åŠ æ¸›é€Ÿæ€§èƒ½ãƒ»æœ€é«˜é€Ÿã¨ã‚‚ã«é«˜æ°´æº–ã€‚"
    },
    "é«˜åŠ é€Ÿè»Šã€Œã‚¸ã‚§ãƒƒãƒˆã‚«ãƒ¼ã€ (ä¾‹: é˜ªç¥5700ç³»)": {
        "max_speed": 110.0, "acc": 4.0, "dec": 4.5, "curve_factor": 4.2,
        "desc": "é§…é–“ãŒçŸ­ã„è·¯ç·šå‘ã‘ã€‚é©šç•°çš„ãªåŠ é€ŸåŠ›ã€‚"
    },
    "ç‰¹æ€¥å‹è»Šä¸¡ (ä¾‹: 683ç³»)": {
        "max_speed": 130.0, "acc": 2.2, "dec": 4.0, "curve_factor": 4.5,
        "desc": "é«˜é€Ÿèµ°è¡Œæ€§èƒ½ã«å„ªã‚ŒãŸç‰¹æ€¥è»Šä¸¡ã€‚"
    },
    "æ–°å¹¹ç·š (ä¾‹: N700S)": {
        "max_speed": 300.0, "acc": 2.6, "dec": 4.5, "curve_factor": 6.0,
        "desc": "ç›´ç·šåŒºé–“ã§ã¯æœ€å¼·ã ãŒã€åœ¨æ¥ç·šã‚«ãƒ¼ãƒ–ã«ã¯å¼±ã„ã€‚"
    }
}

# ==========================================
# ç‰©ç†è¨ˆç®—ãƒ»å¹¾ä½•å­¦ãƒ­ã‚¸ãƒƒã‚¯
# ==========================================
def hubeny_distance(lat1, lon1, lat2, lon2):
    a, b = 6378137.000, 6356752.314
    e2 = (a**2 - b**2) / a**2
    rad_lat1, rad_lon1 = math.radians(lat1), math.radians(lon1)
    rad_lat2, rad_lon2 = math.radians(lat2), math.radians(lon2)
    avg_lat = (rad_lat1 + rad_lat2) / 2.0
    d_lat, d_lon = rad_lat1 - rad_lat2, rad_lon1 - rad_lon2
    W = math.sqrt(1 - e2 * math.sin(avg_lat)**2)
    M, N = a * (1 - e2) / W**3, a / W
    return math.sqrt((d_lat * M)**2 + (d_lon * N * math.cos(avg_lat))**2)

def calculate_radius(p1, p2, p3):
    d12 = hubeny_distance(p2[0], p2[1], p1[0], p1[1])
    d23 = hubeny_distance(p2[0], p2[1], p3[0], p3[1])
    # ãƒ˜ãƒ­ãƒ³ã®å…¬å¼ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
    a = hubeny_distance(p1[0], p1[1], p2[0], p2[1])
    b = hubeny_distance(p2[0], p2[1], p3[0], p3[1])
    c = hubeny_distance(p3[0], p3[1], p1[0], p1[1])
    s = (a+b+c)/2
    val = s*(s-a)*(s-b)*(s-c)
    if val <= 0: return 9999.0
    area = math.sqrt(val)
    if area < 0.01: return 9999.0
    R = (a*b*c)/(4*area)
    return min(R, 6000.0)

def resample_and_analyze(points, spec, interval=25.0):
    if len(points) < 2: return []
    cum_dist = [0.0]
    for i in range(1, len(points)):
        d = hubeny_distance(points[i-1][0], points[i-1][1], points[i][0], points[i][1])
        cum_dist.append(cum_dist[-1] + d)
    
    total = cum_dist[-1]
    if total == 0: return []
    new_dists = np.arange(0, total, interval)
    lats = np.interp(new_dists, cum_dist, [p[0] for p in points])
    lons = np.interp(new_dists, cum_dist, [p[1] for p in points])
    
    track = []
    w = 3 
    for i in range(len(new_dists)):
        if i < w or i >= len(new_dists) - w:
            R = 9999.0
        else:
            R = calculate_radius((lats[i-w], lons[i-w]), (lats[i], lons[i]), (lats[i+w], lons[i+w]))
        
        limit = spec['curve_factor'] * math.sqrt(R)
        limit = max(25.0, min(spec['max_speed'], limit))
        track.append({'dist': new_dists[i], 'limit': limit, 'pattern': 0.0})
    return track

# ==========================================
# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æãƒ­ã‚¸ãƒƒã‚¯ (ã‚¹ãƒãƒ¼ãƒˆé§…çµåˆ)
# ==========================================
def build_network(map_data):
    G = nx.Graph()
    edge_details = {} # (u, v) -> details
    
    # é§…åè§£æ±ºç”¨è¾æ›¸: name -> list of {id: "UniqueName", coords: (lat, lon)}
    known_stations = {}
    
    # è·¯ç·šãƒ‡ãƒ¼ã‚¿ã®äº‹å‰è§£æã¨é§…IDã®è§£æ±º
    lines = map_data.get('line', [])
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: å…¨é§…ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯IDã‚’æ±ºå®š
    # (line_index, point_index) -> unique_station_id
    station_id_map = {} 
    
    # é§…åº§æ¨™è¾æ›¸ (Unique ID -> Coords)
    station_coords = {}

    for line_idx, line in enumerate(lines):
        if line.get('type') == 1: continue 
        line_name = line.get('name', f'è·¯ç·š{line_idx}')
        raw_points = line.get('point', [])
        
        for pt_idx, p in enumerate(raw_points):
            if len(p) >= 4 and p[2] == 's':
                raw_name = p[3]
                lat, lon = p[0], p[1]
                
                # æ—¢å­˜ã®åŒåé§…ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                if raw_name not in known_stations:
                    known_stations[raw_name] = []
                
                found_id = None
                # è¿‘ãã«ã‚ã‚‹åŒåé§…ã‚’æ¢ã™
                for entry in known_stations[raw_name]:
                    dist = hubeny_distance(lat, lon, entry['coords'][0], entry['coords'][1])
                    if dist < SAME_STATION_THRESHOLD:
                        found_id = entry['id']
                        break
                
                if found_id:
                    # è¿‘ãã«è¦‹ã¤ã‹ã£ãŸ -> åŒã˜é§…ã¨ã—ã¦æ‰±ã†
                    unique_id = found_id
                else:
                    # è¦‹ã¤ã‹ã‚‰ãªã„ or é ã„ -> æ–°ã—ã„é§…ã¨ã—ã¦ç™»éŒ²
                    if len(known_stations[raw_name]) == 0:
                        unique_id = raw_name
                    else:
                        # åå‰é‡è¤‡å›é¿: "é§…å (è·¯ç·šå)"
                        unique_id = f"{raw_name} ({line_name})"
                        # ãã‚Œã§ã‚‚è¢«ã‚‹å ´åˆï¼ˆåŒã˜è·¯ç·šã§é ã„å ´æ‰€ã«åŒåé§…ãŒã‚ã‚‹ãªã©ç¨€ãªã‚±ãƒ¼ã‚¹ï¼‰
                        c = 2
                        base_id = unique_id
                        existing_ids = [e['id'] for e in known_stations[raw_name]]
                        while unique_id in existing_ids:
                            unique_id = f"{base_id} {c}"
                            c += 1
                    
                    known_stations[raw_name].append({'id': unique_id, 'coords': (lat, lon)})
                    station_coords[unique_id] = (lat, lon)
                
                station_id_map[(line_idx, pt_idx)] = unique_id

    # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚°ãƒ©ãƒ•æ§‹ç¯‰
    for line_idx, line in enumerate(lines):
        if line.get('type') == 1: continue
        line_name = line.get('name', 'ä¸æ˜')
        raw_points = line.get('point', [])
        
        # ã“ã®è·¯ç·šã®é§…ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        line_stations = []
        for i, p in enumerate(raw_points):
            if (line_idx, i) in station_id_map:
                line_stations.append({
                    'id': station_id_map[(line_idx, i)],
                    'raw_idx': i
                })
        
        # é§…é–“ã‚’æ¥ç¶š
        for i in range(len(line_stations) - 1):
            st1 = line_stations[i]
            st2 = line_stations[i+1]
            u, v = st1['id'], st2['id']
            
            # åŒºé–“åº§æ¨™ã®æŠ½å‡º
            segment_points = []
            for k in range(st1['raw_idx'], st2['raw_idx'] + 1):
                p = raw_points[k]
                segment_points.append((p[0], p[1]))
            
            # è·é›¢è¨ˆç®—
            dist = 0
            for k in range(len(segment_points)-1):
                dist += hubeny_distance(segment_points[k][0], segment_points[k][1],
                                      segment_points[k+1][0], segment_points[k+1][1])
            
            G.add_edge(u, v, weight=dist)
            
            # è©³ç´°ä¿å­˜
            key = tuple(sorted((u, v)))
            edge_details[key] = {
                'points': segment_points,
                'line_name': line_name
            }

    return G, edge_details, station_coords

# ==========================================
# ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¯ãƒ©ã‚¹
# ==========================================
class TrainSim:
    def __init__(self, track, spec):
        self.track = track
        self.spec = spec
        self.dt = 0.5
        self.max_acc = spec['acc'] / 3.6
        self.max_dec = spec['dec'] / 3.6
        self._calc_brake_pattern()
    
    def _calc_brake_pattern(self):
        self.track[-1]['pattern'] = 0.0
        for i in range(len(self.track)-2, -1, -1):
            dd = self.track[i+1]['dist'] - self.track[i]['dist']
            v_next = self.track[i+1]['pattern'] / 3.6
            v_allow = math.sqrt(v_next**2 + 2 * self.max_dec * dd) * 3.6
            self.track[i]['pattern'] = min(v_allow, self.track[i]['limit'])

    def run(self):
        t, x, v = 0.0, 0.0, 0.0
        curr = 0
        total = self.track[-1]['dist']
        while x < total and t < 3600*5: 
            while curr < len(self.track)-1 and self.track[curr+1]['dist'] < x:
                curr += 1
            node = self.track[curr]
            tgt = node['pattern']
            v_ms = v / 3.6
            if v > tgt:
                v_ms -= self.max_dec * self.dt
            elif v < tgt:
                ratio = 1.0
                if v > 35: ratio = 35/v
                if v > 100: ratio *= (100/v)
                v_ms += self.max_acc * ratio * self.dt
            if v_ms < 0: v_ms = 0
            x += v_ms * self.dt
            v = v_ms * 3.6
            t += self.dt
            if x >= total - 2.0 and v < 1.0: break
        return t

def format_time(seconds):
    m, s = divmod(seconds, 60)
    return f"{int(m)}åˆ†{int(s):02d}ç§’"

def sanitize_filename(name):
    return re.sub(r'[\\/:*?"<>|]+', '_', name)

# ==========================================
# ã‚¢ãƒ—ãƒªUI
# ==========================================
st.title("ğŸš† ç©ºæƒ³é‰„é“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ (ç›´é€šãƒ»ã‚¹ãƒãƒ¼ãƒˆé§…çµåˆ)")
st.markdown("é§…åãŒåŒã˜ã§ã‚‚è·é›¢ãŒé›¢ã‚Œã¦ã„ã‚‹å ´åˆã¯åˆ¥ã®é§…ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚")

# --- ãƒ‡ãƒ¼ã‚¿å…¥åŠ› ---
raw_text = st.text_area(
    "ä½œå“ãƒ‡ãƒ¼ã‚¿ã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ (Ctrl+V)",
    height=150,
    placeholder='ã“ã“ã« {"mapinfo": ... } ã‹ã‚‰å§‹ã¾ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’è²¼ã‚Šä»˜ã‘ã¾ã™'
)

if raw_text:
    try:
        try: data = json.loads(raw_text)
        except:
            idx = raw_text.find('{')
            if idx != -1: data = json.loads(raw_text[idx:])
            else: st.stop()
        
        if isinstance(data.get('mapdata'), str):
            map_data = json.loads(data['mapdata'])
        else:
            map_data = data
            
        map_title = data.get('mapinfo', {}).get('name', 'ç©ºæƒ³é‰„é“')
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰ (ã‚¹ãƒãƒ¼ãƒˆçµåˆ)
        G, edge_details, station_coords = build_network(map_data)
        
        # å…¨é§…ãƒªã‚¹ãƒˆï¼ˆã‚½ãƒ¼ãƒˆæ¸ˆã¿ï¼‰
        all_stations_list = sorted(list(G.nodes()))
        
        st.success(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰å®Œäº†: {len(all_stations_list)}é§… (è·é›¢åˆ¤å®šé–¾å€¤: {int(SAME_STATION_THRESHOLD)}m)")
        
        # --- é‹è»¢è¨­å®š ---
        st.subheader("âš™ï¸ é‹è»¢ãƒ—ãƒ©ãƒ³")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            # å‡ºç™ºãƒ»åˆ°ç€é§…ã®é¸æŠ
            dept_st = st.selectbox("å‡ºç™ºé§…", all_stations_list, index=0)
            dest_st = st.selectbox("åˆ°ç€é§…", all_stations_list, index=len(all_stations_list)-1)
            
            # çµŒè·¯è¨ˆç®—
            try:
                route_stations = nx.shortest_path(G, source=dept_st, target=dest_st, weight='weight')
                st.info(f"çµŒè·¯: {' â†’ '.join(route_stations[:5])} ... ({len(route_stations)}é§…)")
            except nx.NetworkXNoPath:
                st.error("çµŒè·¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ç·šè·¯ãŒç¹‹ãŒã£ã¦ã„ã¾ã›ã‚“ã€‚")
                st.stop()
            except Exception:
                st.error("å‡ºç™ºé§…ã¨åˆ°ç€é§…ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
                st.stop()

            # ãƒˆã‚°ãƒ«å¼åœè»Šè¨­å®š
            st.write("â–¼ åœè»Šãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®š")
            btn_col1, btn_col2 = st.columns(2)
            if btn_col1.button("å…¨é¸æŠ"):
                for s in route_stations: st.session_state[f"chk_thru_{s}"] = True
            if btn_col2.button("å…¨è§£é™¤"):
                for s in route_stations: st.session_state[f"chk_thru_{s}"] = False

            with st.container(height=300):
                selected_names = []
                for s in route_stations:
                    key = f"chk_thru_{s}"
                    if key not in st.session_state: st.session_state[key] = True
                    if st.checkbox(s, key=key):
                        selected_names.append(s)

        with col2:
            vehicle_name = st.selectbox("ä½¿ç”¨è»Šä¸¡", list(VEHICLE_DB.keys()))
            spec = VEHICLE_DB[vehicle_name]
            st.caption(f"{spec['desc']}")
            train_type = st.text_input("ç¨®åˆ¥å", value="ç›´é€šç‰¹æ€¥")
            dwell_time = st.slider("åœè»Šæ™‚é–“(ç§’)", 0, 120, 30)

        # --- å®Ÿè¡Œ ---
        st.write("")
        if st.button("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ", type="primary", use_container_width=True):
            if len(selected_names) < 2:
                st.error("åœè»Šé§…ä¸è¶³ã§ã™")
            else:
                final_stops = [s for s in route_stations if s in selected_names]
                if route_stations[0] not in final_stops: final_stops.insert(0, route_stations[0])
                if route_stations[-1] not in final_stops: final_stops.append(route_stations[-1])
                
                # é‡è¤‡æ’é™¤ãƒ»é †åºç¶­æŒ
                seen = set()
                final_stops_ordered = []
                for x in route_stations:
                    if x in final_stops and x not in seen:
                        final_stops_ordered.append(x)
                        seen.add(x)
                final_stops = final_stops_ordered

                st.divider()
                st.subheader(f"ğŸ {dept_st} ç™º {dest_st} è¡Œ ({train_type})")
                
                results = []
                progress_bar = st.progress(0)
                
                for i in range(len(final_stops) - 1):
                    progress_bar.progress((i+1)/(len(final_stops)-1))
                    
                    s_start = final_stops[i]
                    s_end = final_stops[i+1]
                    
                    sub_path = nx.shortest_path(G, s_start, s_end, weight='weight')
                    combined_points = []
                    
                    for k in range(len(sub_path)-1):
                        u, v = sub_path[k], sub_path[k+1]
                        key = tuple(sorted((u, v)))
                        details = edge_details[key]
                        pts = details['points']
                        
                        # å‘ãåˆ¤å®š
                        u_coord = station_coords[u]
                        d_start = hubeny_distance(pts[0][0], pts[0][1], u_coord[0], u_coord[1])
                        d_end = hubeny_distance(pts[-1][0], pts[-1][1], u_coord[0], u_coord[1])
                        
                        if d_end < d_start: pts = pts[::-1]
                        
                        if combined_points: combined_points.extend(pts[1:])
                        else: combined_points.extend(pts)
                            
                    track = resample_and_analyze(combined_points, spec)
                    if not track: continue
                    
                    sim = TrainSim(track, spec)
                    run_sec = sim.run()
                    
                    is_last = (i == len(final_stops) - 2)
                    cur_dwell = 0 if is_last else dwell_time
                    total_leg = run_sec + cur_dwell
                    dist_km = track[-1]['dist'] / 1000.0
                    
                    results.append({
                        'å‡ºç™º': s_start, 'åˆ°ç€': s_end,
                        'è·é›¢(km)': round(dist_km, 2),
                        'èµ°è¡Œæ™‚é–“': format_time(run_sec),
                        'åœè»Šæ™‚é–“': f"{cur_dwell}ç§’",
                        'è¨ˆ': format_time(total_leg),
                        '_run': run_sec, '_dwell': cur_dwell
                    })

                progress_bar.progress(100)
                
                if results:
                    df = pd.DataFrame(results)
                    sum_run = df['_run'].sum()
                    sum_dwell = df['_dwell'].sum()
                    total_all = sum_run + sum_dwell
                    
                    sum_row = pd.DataFrame([{
                        'å‡ºç™º': 'ã€åˆè¨ˆã€‘', 'åˆ°ç€': '',
                        'è·é›¢(km)': df['è·é›¢(km)'].sum(),
                        'èµ°è¡Œæ™‚é–“': format_time(sum_run),
                        'åœè»Šæ™‚é–“': format_time(sum_dwell),
                        'è¨ˆ': format_time(total_all)
                    }])
                    
                    df_disp = pd.concat([df, sum_row], ignore_index=True)
                    df_disp = df_disp[['å‡ºç™º', 'åˆ°ç€', 'è·é›¢(km)', 'èµ°è¡Œæ™‚é–“', 'åœè»Šæ™‚é–“', 'è¨ˆ']]
                    
                    st.dataframe(df_disp, use_container_width=True)
                    
                    output = BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        df_disp.to_excel(writer, sheet_name=sanitize_filename(train_type), index=False)
                    
                    st.download_button(
                        "Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=output.getvalue(),
                        file_name=f"ç›´é€š_{sanitize_filename(dept_st)}_{sanitize_filename(dest_st)}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
